---
---
References
==========

@inproceedings{Tu:BUG,
  author    = {Hoang, Anh-Tu and Tran, Minh-Triet and Duong, Anh-Duc and Echizen, Isao},
  booktitle = {2012 Eighth International Conference on Computational Intelligence and Security},
  title     = {An Indexed Bottom-up Approach for Publishing Anonymized Data},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {641-645},
  doi       = {10.1109/CIS.2012.148},
  abstract  = {Sharing information is one of the most important parts of social activities. However, sharing information can leak users' information. Removing all direct identifiers is not enough. Sweeney proposed an approach that applying k-anonymity to protect users' identities from linking attack. Sweeney`s algorithm finds out the optimal anonymized dataset through minimal distortion metric. Other authors proposed other optimal algorithms but their proposals are still impractical due to their high computational cost. Another approach is to release the minimal anonymized dataset by applying some heuristics. Wang and Fung proposed Bottom-up Generalization and Top-down Specialization (TDS) to publish a minimal anonymized dataset with information loss metric, whose performance is more efficient. However, these algorithms still have some limitations. In this paper, we propose an algorithm to publish anonymized datasets through bottom-up generalization approach and information loss data metric. Our algorithm can save time by storing statistical information for later usage. The experimental results is performanced on Adult dataset, which is used in all former algorithms. Experimental results show that our algorithm can process 949,662 records dataset in 42.219s. Classification error on anonymized data, which is created by our algorithm, is lower than Wang's algorithm 3.8%.}
}

@inproceedings{Tu:watermark-bug,
  author    = {Hoang, Anh-Tu
               and Nguyen-Son, Hoang-Quoc
               and Tran, Minh-Triet
               and Echizen, Isao},
  editor    = {Shi, Yun Qing
               and Kim, Hyoung-Joong
               and P{\'e}rez-Gonz{\'a}lez, Fernando},
  title     = {Detecting Traitors in Re-publishing Updated Datasets},
  booktitle = {Digital-Forensics and Watermarking},
  year      = {2014},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {205--220},
  abstract  = {The application of fingerprinting techniques to relational data cannot protect personal information against a collusion attack, in which the attacker has access to a set of published data. The general fingerprinting techniques such as Li et at.'s, Guo et al.'s, and Schrittwieser et al.'s focus on detecting the traitor, who leaked the data. Among them, Schrittwieser et al.'s fingerprinting technique combines {\$}{\$}k{\$}{\$}-anonymity and full-domain generalization in order to not only detect traitors but also protect personal records. However, the technique has two main limitations. First, it does not allow the data provider to insert or delete records from the original data. Secondly, it does not create enough fingerprints for data recipients. To overcome these limitations, in this paper, we propose an ({\$}{\$}{\backslash}alpha ,k{\$}{\$})-privacy protection model, an extension of {\$}{\$}m{\$}{\$}-invariance and ({\$}{\$}{\backslash}alpha , k{\$}{\$})-anonymity, and a new top-down ({\$}{\$}{\backslash}alpha , k{\$}{\$})-privacy fingerprinting algorithm based on that model. The model not only protects sensitive personal information against collusion attacks but also allows data providers to republish their updated original data without degrading the privacy protection. The algorithm embeds fingerprints in the generalized data and extracts them from leaked data to detect the traitors. We extensively evaluate the proposed algorithm on our own built software. The evaluation results show that our algorithm creates more fingerprints than Schrittwieser et al.'s algorithm (64000 vs 1536) while achieving the same generalized data quality. Moreover, our ({\$}{\$}{\backslash}alpha , k{\$}{\$})-privacy algorithm creates generalized data even in the case of having small number of distinct sensitive values in the original data without adding faked records as in {\$}{\$}m{\$}{\$}-invariance.},
  isbn      = {978-3-662-43886-2},
  doi       = {10.1007/978-3-662-43886-2_15}
}


@inproceedings{Tu:CDGA,
  author    = {Hoang, Anh-Tu and Carminati, Barbara and Ferrari, Elena},
  booktitle = {2019 IEEE 5th International Conference on Collaboration and Internet Computing (CIC)},
  title     = {Cluster-Based Anonymization of Directed Graphs},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {91-100},
  doi       = {10.1109/CIC48465.2019.00020},
  abstract  = {Social network providers anonymize graphs storing users' relationships to protect users from being re-identified. Despite the fact that most of the relationships are directed (e.g., follows), few works (e.g., the Paired-degree [1] and K-In&Out-Degree Anonymity [2]) have been designed to work with directed graphs. In this paper, we show that given a graph, DGA [1]and DSNDG-KIODA [2] are not always able to generate its anonymized version. We overcome this limitation by presenting the Cluster-based Directed Graph Anonymization Algorithm(CDGA) and prove that, by choosing the appropriate parameters, CDGA can generate an anonymized graph satisfying both the Paired k-degree [1] and K-In&Out-Degree Anonymity [2]. Also, we present the Out-and In-Degree Information Loss Metric to minimize the number of changes made to anonymize the graph. We conduct extensive experiments on three real-life data sets to evaluate the effectiveness of CDGA and compare the quality of the graphs anonymized by CDGA, DGA, and DSNDG-KIODA. The experimental results show that we can generate anonymized graphs, by modifying less than 0.007% of edges in the original graph.}
}

@inproceedings{Tu:CKGA,
  author    = {Hoang, Anh-Tu
               and Carminati, Barbara
               and Ferrari, Elena},
  editor    = {Conti, Mauro
               and Zhou, Jianying
               and Casalicchio, Emiliano
               and Spognardi, Angelo},
  title     = {Cluster-Based Anonymization of Knowledge Graphs},
  booktitle = {Applied Cryptography and Network Security},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {104--123},
  abstract  = {While knowledge graphs (KGs) are getting popular as they can formalize many types of users' data in social networks, sharing these data may reveal users' identities. Although many protection models have been presented to protect users in anonymized data, they are unsuitable to protect the users in KGs. To cope with this problem, we propose k-AttributeDegree (k-ad), a model to protect users' identities in anonymized KGs. We further present information loss metrics tailored to KGs and a cluster-based anonymization algorithm to generate anonymized KGs satisfying k-ad. Finally, we conduct experiments on five real-life data sets to evaluate our algorithm and compare it with previous work.},
  isbn      = {978-3-030-57878-7},
  doi       = {10.1007/978-3-030-57878-7_6}
}

@inproceedings{Tu:text-anony,
  author    = {Nguyen-Son, Hoang-Quoc
               and Hoang, Anh-Tu
               and Tran, Minh-Triet
               and Yoshiura, Hiroshi
               and Sonehara, Noboru
               and Echizen, Isao},
  editor    = {Shi, Yun Qing
               and Kim, Hyoung-Joong
               and P{\'e}rez-Gonz{\'a}lez, Fernando},
  title     = {Anonymizing Temporal Phrases in Natural Language Text to be Posted on Social Networking Services},
  booktitle = {Digital-Forensics and Watermarking},
  year      = {2014},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {437--451},
  abstract  = {Time-related information in text posted on-line is one type of personal information targeted by attackers, one reason that sharing information online can be risky. Therefore, time information should be anonymized before it is posted on social networking services. One approach to anonymizing information is to replace sensitive phrases with anonymous phrases, but attackers can usually spot such anonymization due to its unnaturalness. Another approach is to detect temporal passages in the text, but removal of these passages can make the meaning of the text unnatural. We have developed an algorithm that can be used to anonymize time-related personal information by removing the temporal passages when doing so will not change the natural meaning of the message. The temporal phrases are detected by using machine-learned patterns, which are represented by a subtree of the sentence parsing tree. The temporal phrases in the parsing tree are distinguished from other parts of the tree by using temporal taggers integrated into the algorithm. In an experiment with 4008 sentences posted on a social network, 84.53 {\%} of them were anonymized without changing their intended meaning. This is significantly better than the 72.88 {\%} rate of the best previous temporal phrase detection algorithm. Of the learned patterns, the top ten most common ones were used to detect 87.78 {\%} the temporal phrases. This means that only some of the most common patterns can be used to the anonymize temporal phrases in most messages to be posted on an SNS. The algorithm works well not only for temporal phrases in text posted on social networks but also for other types of phrases (such as location and objective ones), other areas (religion, politics, military, etc.), and other languages.},
  isbn      = {978-3-662-43886-2},
  doi       = {10.1007/978-3-662-43886-2_31}
}

@inproceedings{Tu:kwtad,
  author    = {Hoang, Anh-Tu and Carminati, Barbara and Ferrari, Elena},
  booktitle = {2021 IEEE 37th International Conference on Data Engineering (ICDE)},
  title     = {Privacy-Preserving Sequential Publishing of Knowledge Graphs},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {2021-2026},
  doi       = {10.1109/ICDE51399.2021.00194},
  abstract  = {Knowledge graphs (KGs) are widely shared because they can model both users' attributes as well as their relationships. Unfortunately, adversaries can re-identify their victims in these KGs by using a rich background knowledge about not only the victims' attributes but also their relationships. A preliminary work to deal with this issue has been proposed in [1] which anonymizes both user attributes and relationships, but this is not enough. Indeed, adversaries can still re-identify target users if data providers publish new versions of their anonymized KGs. We remedy this problem by presenting the k w -Time-Varying Attribute Degree (k w -tad) principle that prevents adversaries from re-identifying any user appearing in w continuous anonymized KGs with a confidence higher than 1/ k . Moreover, we introduce the Cluster-based Time-Varying Knowledge Graph Anonymization Algorithm to generate anonymized KGs satisfying k w -tad. Finally, we prove that even if data providers insert/re-insert/update/delete their users, the users are protected by k w -tad.}
}

@inproceedings{tu:van,
  author   = {Nguyen, Van and De Beenhouwer, Jan and Bazrafkan, Shabab and Hoang, Anh-Tu and Wassenbergh, S and Sijbers, Jan},
  booktitle = {CTMeeting-2020},
  year     = {2020},
  month    = {},
  pages    = {},
  title    = {BeadNet: a network for automated spherical marker detection in radiographs for geometry calibration},
  abstract = {Spherical markers are commonly used by phantombased calibration methods for X-ray CT systems. Defining the position of the marker centers is therefore crucial to estimate the geometry parameters accurately. Although marker bearing structures are often built from materials of low X-ray attenuation, they still overlap with the marker in projection images. This complicates accurate determination of the marker centers. In this work, we explore the technique of Deep Learning to extract the marker center coordinates from the calibration projections. By training a Deep Learning network for each marker center coordinate, 2D positions of the marker are derived. With simulated as well as real experiments, it is shown that the trained Deep Learning networks can be used to accurately estimate the marker positions, and hence also the geometry of the X-ray CT system.}
}

@inproceedings{tu:tops,
  author    = {Hoang, Anh-Tu and Carminati, Barbara and Ferrari, Elena},
  booktitle = {the ACM Transactions on Privacy and Security (TOPS)},
  title     = {Time-Aware Anonymization of Knowledge Graphs (Accepted)},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {},
  doi       = {10.1145/3563694},

  abstract  = {Knowledge graphs (KGs) play an essential role in data sharing because they can model both users' attributes and their relationships. KGs can tailor many data analyses, such as classification where a sensitive attribute is selected and the analyst analyzes the associations between users and the sensitive attribute's values (aka sensitive values).     Data providers anonymize their KGs and share the anonymized versions to protect users' privacy. Unfortunately, an adversary can exploit these attributes and relationships to infer sensitive information by monitoring either one or many snapshots of a KG. To cope with this issue, in this paper, we introduce $(k,l)$-Sequential Attribute Degree ($(k,l)$-sad), an extension of the $k^w$-tad principle\cite{Tu:kwtad}, to ensure that sensitive values of re-identified users are diverse enough to prevent them from being inferred with a confidence higher than $\frac{1}{l}$ even though adversaries monitor all published KGs. In addition, we develop the Time-Aware Knowledge Graph Anonymization Algorithm to anonymize  KGs such that all published anonymized versions of a KG satisfy the $(k,l)$-sad principle, by, at the same time, preserving the utility of the anonymized data. We conduct experiments on four real-life datasets to show the effectiveness of our proposal and compare it with $k^w$-tad.}
}
